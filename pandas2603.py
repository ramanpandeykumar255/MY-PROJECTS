# -*- coding: utf-8 -*-
"""Pandas2603.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b53Hwf-M-cUh3jMG3D8EyiOYTT21tkd0
"""

# Pandas :
# it is used to perform data analysis and Manipulation
# Pandas is also a open source libraray

# Why Pnadas ;
# Pandas is a Python package that provides fast, flexible, and
# expressive data structures designed to make working with "relational" or "labeled" data both easy and intuitive.
# It provides the ability to work with tabular data.
# Tabular data : the data whcih is having rows and columns

!pip install pandas

import pandas as pd

# Series  : Series is a one dimentional labbeled arrays

sub = ["HTML", "CSS", "Python", "Django", "SQL", "Maths", "science"]

ser = pd.Series(data= sub)

ser

type(ser)

ser

ser[3]

ser[4]

ser[1]

ser.index = ["p", "q", "r", "s", "t", "u", "v"]

ser

ser["u"]

ser[5]

type(ser)

ser["s"]



# DataFrame ; 2D Labelled arrys is known as data frame which is having label and columns.
# If we combine multiple series we will be getting Datafrmae.
# it is a most widely used  data structures.

import numpy as np

import pandas as pd

arr = np.random.randint(10, 100, size = (8,6))

df = pd.DataFrame(data= arr)

type(df)

df.shape

df.dtypes

df

df[4]

df[2]



"a b c d e f g h".split()

df.index = "a b c d e f g h".split()

df

df[3]

df.columns = ["p", "q", "r", "s", "t", "u"]

df

df.columns

df.index

import numpy as np
import pandas as pd
arr = np.random.randint(10, 100, size = (8,6))
df = pd.DataFrame(arr)

df

df[2]

df.columns = ["p", "q", "r", "s", "t", "u"]

df["r"]

df["s"]

# for extracting rows
# loc
# iloc
df.iloc[2]

df.iloc[3]

df.iloc[5]

df["t"]

df.index = "a b c d e f g h".split()

df.loc["d"]

df

df.iloc[3]

df.iloc[1:3, 1:3]

df

df.iloc[0:2, -3:-1]

df.iloc[0, 0]

df.iloc[5:7,2:4]

df.iloc[-3:-1, -4:-2]

df.iloc[:-2]

df

df.head()

df.head(n= 3)

df.head(n = 2)

df.tail()

df.tail(n = 2)

df.tail(3)

df.sample()

df.sample(n = 4)

df["q"]

df[["q", "r"]]

df[["r", "s", "t"]]

df["v"] = 100

df["w"] = df["p"] + df["q"]

df

df

df = df.drop("q", axis=1)

df

df.drop(columns="v",inplace=True)

df

df.drop(labels="b", inplace=True)

df

df = df.drop(index="e")

df

df.iloc[1:4, 1:4][["q", "r"]]

df

df

# Masking : Boolean Indexing ; True, False

df>50

df < 60

df["p"]

df.p

df.r >= 50

df>60

df[df>60]

df[~(df>60)]

df["q"] > 30

df.s < 60

(df["q"] > 30) & (df.s < 60)

df[(df["q"] > 30) & (df.s < 60)][["q", "r", "s"]]

new_array = df.values
new_array



# reading - we can read our data

pd.read_csv(filepath_or_buffer="iris.csv")

df2 = pd.read_csv("https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv")

df = pd.read_excel("Superstore08.xlsx")

df.shape

df2.shape

df2.head(n = 6)

df.tail(n = 2)

df.sample(n = 3)

df2.head(4)

type(df2)

df2.dtypes

df.columns

df.index

df2.columns

df2.info()



df2.describe()



import pandas as pd

df = pd.read_csv("iris.csv")



df = pd.read_csv(r"C:\Users\ALI\Desktop\readingdemo\iris.csv")

df

df = pd.read_csv("C:\\Users\\ALI\\Desktop\\readingdemo\\iris.csv")

df

df = pd.read_csv("C:/Users/ALI/Desktop/readingdemo/iris.csv")

df

df = pd.read_csv("https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv")

df["species"]

df.species.nunique()

df.species.unique()

df

df.species == "setosa"

df[df.species == "setosa"]

virginica = df[df.species == "virginica"]

virginica.shape



# arregate Functions

df.sepal_length.min()

df.petal_length.max()

df.sepal_width.sum()

import numpy as np

np.round(df.petal_width.mean(), 3)

# sorting

df.sort_values(by="sepal_length", inplace=True)

df = df.sort_index()

df

df

df.sort_values(by = "sepal_length" , ascending=False)

df.sort_values(by=["sepal_length", "sepal_width"], ascending=[True, False])

df.sort_values(by=["sepal_length", "sepal_width"], ascending=[False, True])

# apply

df["species_length"] = df.species.apply(len)

df

df.sepal_width = df.sepal_width.apply(lambda s: s*2)

df

def double(g):
    return g+g



double(5)

double(3)



df.apply(func=double)





import pandas as pd

df_profit = pd.read_excel("account.xlsx")[:10]

df_profit.drop(index=[0, 1, 2, 3], inplace=True)

df_profit

pd.read_excel("account.xlsx", sheet_name="Sales")



df_tables = pd.read_html("https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_and_their_capitals_in_native_languages")

df_tables

df_tables[3]

df_c = df_tables[5]

df_c.drop(columns=["Capital (endonym)", "Official or native language(s) (alphabet/script)"], inplace=True)

df_c =  df_c.drop(labels="Country (endonym)", axis=1)

df_c

df_c.columns = ["Country", "Capital"]

df_c

df_c.head()

import pandas as pd

df_tables = pd.read_html("https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_and_their_capitals_in_native_languages")

df_b = df_tables[4]

df_b =  df_b.drop(columns=["Country (endonym)", "Capital (endonym)"])

df_b.columns =  df_b.columns.map(lambda x: x.split('(')[0].strip())

df_b

def replacebracket(d):
    return d.split('[')[0].strip()

p = "Bermuda[2]"

replacebracket(p)

df_b.Country = df_b.Country.apply(replacebracket)

df_b



# iris

df = pd.read_json('iris.json')

df

# grouping data together

df.head()

df.aggregate("min")

df.sepalLength.min()

df.agg("max")

df2 = df.drop(labels="species", axis=1)

df2.head()

df2.agg("median")

df2.agg("mean")

df.species.unique()

df2.agg(["min", "max", "mean", "median"])



df.sepalWidth.mean()



df[df.species == "virginica"]["sepalWidth"].mean()



# group by

grp_obj = df.groupby(by="species")

grp_obj.min()



df[df.species == "setosa"]["petalWidth"].min()



grp_obj.max()

grp_obj.mean()



grp_obj.agg(["min", "max", "mean", "median"]).T



# Concat/ Merge data frames

df

import numpy as np

df3 = pd.DataFrame(np.random.randint(0, 7, size = (10, 4)))

df3["species"] =  "New species"

df3

df3.columns =  df.columns

df3



# concat

df3

pd.concat([df, df3])

df4 = pd.concat([df, df3] , axis=1)

df4

{4, 5, 6}

# merge

df6 = pd.DataFrame({
    'S_name' : ["Mohit", "jatin", "Prateek", "Mohit"],
    'CGPA' : [2, 4, 5, 3]
 })

df6

df7 = pd.DataFrame({
    'T_name' : ["Mohit", "jatin", "Prateek", "Mohit"],
    'CGPA' : [3, 6, 8, 9]
 })

df7



df6.merge(df7)

df6.merge(df7, how="left")

df6.merge(df7, how="right")

df6.merge(df7, how="outer")

df6.merge(df7, how="cross")



# handling missing values
# detaction

# treatment
# drop missing values
# fill missing values

df4.isnull().sum()

df4.sepalLength.isna().sum()

df4.sepalLength.dropna()

df4.dropna()



nan_id = np.random.randint(0,150, 50)

df.sepalLength[nan_id] = np.nan

df.sepalLength[:30]

df.sepalLength[:30].fillna("mobile")

np.round(df.sepalLength.mean(), 1)

df.sepalLength = df.sepalLength.fillna(value=np.round(df.sepalLength.mean(), 1))

df.isna().sum()



# saving

df.to_csv("my_final_data.csv", index=False)

ls

df7.to_excel("my_merged_data.xlsx", index=False, sheet_name="Sales data")

